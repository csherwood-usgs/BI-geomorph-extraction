{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI-geomorph-extraction\n",
    "\n",
    "Extract barrier island metrics along transects for Bayesian Network Deep Dive\n",
    "\n",
    "Requires: python 3, ArcPy\n",
    "\n",
    "Author: Emily Sturdivant\n",
    "\n",
    "email: esturdivant@usgs.gov; bgutierrez@usgs.gov\n",
    "\n",
    "Notes:\n",
    "- Run in ArcGIS Pro python 3 environment (access as: \\ArcGIS\\Pro\\bin\\Python\\Scripts\\proenv);\n",
    "- Spatial reference used is NAD 83 UTM 19N: arcpy.SpatialReference(26918)\n",
    "    \n",
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arcpy\n",
    "import CoastalVarExtractor.functions_warcpy as fwa\n",
    "import CoastalVarExtractor.functions as fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If you refuse to install:\n",
    "\n",
    "```python\n",
    "mod_path = \"C:\\Users\\esturdivant\\Code\\BI-geomorph-extraction\" # replace with path to module\n",
    "sys.path.append(mod_path)\n",
    "import CoastalVarExtractor.functions_warcpy as fwa\n",
    "import CoastalVarExtractor.functions as fun\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables\n",
    "\n",
    "Based on the project directory, and the site and year you have input, setvars.py will set a bunch of variables as the names of folders, files, and fields. 1) set-up the project folder and paths: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site: Fisherman\n",
      "year: 2014\n",
      "setvars.py initialized variables.\n"
     ]
    }
   ],
   "source": [
    "from CoastalVarExtractor.setvars import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transect-averaged values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting feature class to array...\n",
      "Converting array to dataframe...\n",
      "Header of transects dataframe (rows 1-5 out of 194: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Azimuth</th>\n",
       "      <th>LCI90</th>\n",
       "      <th>LR2</th>\n",
       "      <th>LRR</th>\n",
       "      <th>LSE</th>\n",
       "      <th>TransOrder</th>\n",
       "      <th>TransectId</th>\n",
       "      <th>sort_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sort_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Azimuth  LCI90  LR2  LRR  LSE  TransOrder  TransectId  sort_ID\n",
       "sort_ID                                                                \n",
       "1            NaN    NaN  NaN  NaN  NaN         NaN         NaN        1\n",
       "2            NaN    NaN  NaN  NaN  NaN         NaN         NaN        2\n",
       "3            NaN    NaN  NaN  NaN  NaN         NaN         NaN        3\n",
       "4            NaN    NaN  NaN  NaN  NaN         NaN         NaN        4\n",
       "5            NaN    NaN  NaN  NaN  NaN         NaN         NaN        5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Create trans_df\n",
    "trans_df = fwa.FCtoDF(extendedTrans, id_fld=tID_fld, extra_fields=extra_fields)\n",
    "trans_df.to_pickle(os.path.join(scratch_dir, 'trans_df.pkl'))\n",
    "print(\"Header of transects dataframe (rows 1-5 out of {}: \".format(len(trans_df)))\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header of transects dataframe (rows 1-5 out of 194): \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Azimuth</th>\n",
       "      <th>LCI90</th>\n",
       "      <th>LR2</th>\n",
       "      <th>LRR</th>\n",
       "      <th>LSE</th>\n",
       "      <th>TransOrder</th>\n",
       "      <th>TransectId</th>\n",
       "      <th>sort_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sort_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Azimuth  LCI90  LR2  LRR  LSE  TransOrder  TransectId  sort_ID\n",
       "sort_ID                                                                \n",
       "1            NaN    NaN  NaN  NaN  NaN         NaN         NaN        1\n",
       "2            NaN    NaN  NaN  NaN  NaN         NaN         NaN        2\n",
       "3            NaN    NaN  NaN  NaN  NaN         NaN         NaN        3\n",
       "4            NaN    NaN  NaN  NaN  NaN         NaN         NaN        4\n",
       "5            NaN    NaN  NaN  NaN  NaN         NaN         NaN        5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Header of transects dataframe (rows 1-5 out of {}): \".format(len(trans_df)))\n",
    "trans_df.head()\n",
    "# Why is the length 175, but the sort_ID values go up to 180?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add XY and Z/slope from DH, DL, SL points within 10m of transects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Joining shoreline points to transects...\n",
      "...duration at transect 100: 0:0:22.1 seconds\n",
      "Duration: 0:0:41.9 seconds\n",
      "\n",
      "Joining DH points to transects:\n",
      "Getting name of Z field...\n",
      "Looking for field _z\n",
      "Looping through transects to find nearest point within 25 meters...\n",
      "Duration at transect 100: 0:0:14.4 seconds\n",
      "Duration: 0:0:26.1 seconds\n",
      "\n",
      "Joining DL points to transects:\n",
      "Getting name of Z field...\n",
      "Looking for field _z\n",
      "Looping through transects to find nearest point within 25 meters...\n",
      "Duration at transect 100: 0:0:13.4 seconds\n",
      "Duration: 0:0:24.2 seconds\n",
      "\n",
      "Armoring file either missing or empty so we will proceed without armoring data. If shorefront tampering is present at this site, cancel the operations to digitize.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Azimuth</th>\n",
       "      <th>LCI90</th>\n",
       "      <th>LR2</th>\n",
       "      <th>LRR</th>\n",
       "      <th>LSE</th>\n",
       "      <th>TransOrder</th>\n",
       "      <th>TransectId</th>\n",
       "      <th>SL_x</th>\n",
       "      <th>SL_y</th>\n",
       "      <th>Bslope</th>\n",
       "      <th>...</th>\n",
       "      <th>DH_snapX</th>\n",
       "      <th>DH_snapY</th>\n",
       "      <th>DL_x</th>\n",
       "      <th>DL_y</th>\n",
       "      <th>DL_z</th>\n",
       "      <th>DL_snapX</th>\n",
       "      <th>DL_snapY</th>\n",
       "      <th>Arm_x</th>\n",
       "      <th>Arm_y</th>\n",
       "      <th>Arm_z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sort_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413851.177269</td>\n",
       "      <td>4.107531e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413809.698456</td>\n",
       "      <td>4.107514e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413778.475432</td>\n",
       "      <td>4.107478e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413746.021688</td>\n",
       "      <td>4.107456e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413702.743869</td>\n",
       "      <td>4.107442e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Azimuth  LCI90  LR2  LRR  LSE  TransOrder  TransectId           SL_x  \\\n",
       "sort_ID                                                                         \n",
       "1            NaN    NaN  NaN  NaN  NaN         NaN         NaN  413851.177269   \n",
       "2            NaN    NaN  NaN  NaN  NaN         NaN         NaN  413809.698456   \n",
       "3            NaN    NaN  NaN  NaN  NaN         NaN         NaN  413778.475432   \n",
       "4            NaN    NaN  NaN  NaN  NaN         NaN         NaN  413746.021688   \n",
       "5            NaN    NaN  NaN  NaN  NaN         NaN         NaN  413702.743869   \n",
       "\n",
       "                 SL_y  Bslope  ...    DH_snapX  DH_snapY  DL_x  DL_y  DL_z  \\\n",
       "sort_ID                        ...                                           \n",
       "1        4.107531e+06     NaN  ...         NaN       NaN   NaN   NaN   NaN   \n",
       "2        4.107514e+06     NaN  ...         NaN       NaN   NaN   NaN   NaN   \n",
       "3        4.107478e+06     NaN  ...         NaN       NaN   NaN   NaN   NaN   \n",
       "4        4.107456e+06     NaN  ...         NaN       NaN   NaN   NaN   NaN   \n",
       "5        4.107442e+06     NaN  ...         NaN       NaN   NaN   NaN   NaN   \n",
       "\n",
       "         DL_snapX  DL_snapY  Arm_x  Arm_y  Arm_z  \n",
       "sort_ID                                           \n",
       "1             NaN       NaN    NaN    NaN    NaN  \n",
       "2             NaN       NaN    NaN    NaN    NaN  \n",
       "3             NaN       NaN    NaN    NaN    NaN  \n",
       "4             NaN       NaN    NaN    NaN    NaN  \n",
       "5             NaN       NaN    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Add XY and Z/slope from DH, DL, SL points within 10m of transects\n",
    "sl2trans_df = fwa.add_shorelinePts2Trans(extendedTrans, ShorelinePts, shoreline, tID_fld, proximity=pt2trans_disttolerance)\n",
    "sl2trans_df.to_pickle(os.path.join(scratch_dir, 'sl2trans.pkl'))\n",
    "fwa.DFtoFC(sl2trans_df, os.path.join(arcpy.env.scratchGDB, 'pts2trans_SL'), spatial_ref=utmSR, id_fld=tID_fld, xy=[\"SL_x\", \"SL_y\"], keep_fields=['Bslope'])\n",
    "\n",
    "dh2trans_df = fwa.find_ClosestPt2Trans_snap(extendedTrans, dhPts, trans_df, 'DH', tID_fld, proximity=pt2trans_disttolerance)\n",
    "dh2trans_df.to_pickle(os.path.join(scratch_dir, 'dh2trans.pkl'))\n",
    "fwa.DFtoFC(dh2trans_df, os.path.join(arcpy.env.scratchGDB, 'ptSnap2trans_DH'), spatial_ref=utmSR, id_fld=tID_fld, xy=[\"DH_snapX\", \"DH_snapY\"], keep_fields=['DH_z'])\n",
    "\n",
    "dl2trans_df = fwa.find_ClosestPt2Trans_snap(extendedTrans, dlPts, trans_df, 'DL', tID_fld, proximity=pt2trans_disttolerance)\n",
    "dl2trans_df.to_pickle(os.path.join(scratch_dir, 'dl2trans.pkl'))\n",
    "fwa.DFtoFC(dl2trans_df, os.path.join(arcpy.env.scratchGDB, 'ptSnap2trans_DL'), spatial_ref=utmSR, id_fld=tID_fld, xy=[\"DL_snapX\", \"DL_snapY\"], keep_fields=['DL_z'])\n",
    "\n",
    "arm2trans_df = fwa.ArmorLineToTrans_PD(extendedTrans, armorLines, sl2trans_df, tID_fld, proj_code, elevGrid_5m)\n",
    "arm2trans_df.to_pickle(os.path.join(scratch_dir, 'arm2trans.pkl'))\n",
    "\n",
    "#%% Add all the positions to the trans_df\n",
    "trans_df = fun.join_columns_id_check(trans_df, sl2trans_df, tID_fld)\n",
    "trans_df = fun.join_columns_id_check(trans_df, dh2trans_df, tID_fld)\n",
    "trans_df = fun.join_columns_id_check(trans_df, dl2trans_df, tID_fld)\n",
    "trans_df = fun.join_columns_id_check(trans_df, arm2trans_df, tID_fld)\n",
    "trans_df.to_pickle(os.path.join(scratch_dir, 'trans_df_beachmetrics.pkl'))\n",
    "\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add all the positions to the trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trans_df = pd.read_pickle(os.path.join(scratch_dir, 'trans_df_beachmetrics.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Azimuth</th>\n",
       "      <th>LCI90</th>\n",
       "      <th>LR2</th>\n",
       "      <th>LRR</th>\n",
       "      <th>LSE</th>\n",
       "      <th>TransOrder</th>\n",
       "      <th>TransectId</th>\n",
       "      <th>SL_x</th>\n",
       "      <th>SL_y</th>\n",
       "      <th>Bslope</th>\n",
       "      <th>...</th>\n",
       "      <th>Arm_z</th>\n",
       "      <th>DH_zmhw</th>\n",
       "      <th>DL_zmhw</th>\n",
       "      <th>Arm_zmhw</th>\n",
       "      <th>DistDL</th>\n",
       "      <th>DistDH</th>\n",
       "      <th>DistArm</th>\n",
       "      <th>uBW</th>\n",
       "      <th>uBH</th>\n",
       "      <th>ub_feat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sort_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413851.177269</td>\n",
       "      <td>4.107531e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413809.698456</td>\n",
       "      <td>4.107514e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413778.475432</td>\n",
       "      <td>4.107478e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413746.021688</td>\n",
       "      <td>4.107456e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>413702.743869</td>\n",
       "      <td>4.107442e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Azimuth  LCI90  LR2  LRR  LSE  TransOrder  TransectId           SL_x  \\\n",
       "sort_ID                                                                         \n",
       "1            NaN    NaN  NaN  NaN  NaN         NaN         NaN  413851.177269   \n",
       "2            NaN    NaN  NaN  NaN  NaN         NaN         NaN  413809.698456   \n",
       "3            NaN    NaN  NaN  NaN  NaN         NaN         NaN  413778.475432   \n",
       "4            NaN    NaN  NaN  NaN  NaN         NaN         NaN  413746.021688   \n",
       "5            NaN    NaN  NaN  NaN  NaN         NaN         NaN  413702.743869   \n",
       "\n",
       "                 SL_y  Bslope   ...     Arm_z  DH_zmhw  DL_zmhw  Arm_zmhw  \\\n",
       "sort_ID                         ...                                         \n",
       "1        4.107531e+06     NaN   ...       NaN      NaN      NaN       NaN   \n",
       "2        4.107514e+06     NaN   ...       NaN      NaN      NaN       NaN   \n",
       "3        4.107478e+06     NaN   ...       NaN      NaN      NaN       NaN   \n",
       "4        4.107456e+06     NaN   ...       NaN      NaN      NaN       NaN   \n",
       "5        4.107442e+06     NaN   ...       NaN      NaN      NaN       NaN   \n",
       "\n",
       "         DistDL  DistDH  DistArm  uBW  uBH  ub_feat  \n",
       "sort_ID                                              \n",
       "1           NaN     NaN      NaN  NaN  NaN      NaN  \n",
       "2           NaN     NaN      NaN  NaN  NaN      NaN  \n",
       "3           NaN     NaN      NaN  NaN  NaN      NaN  \n",
       "4           NaN     NaN      NaN  NaN  NaN      NaN  \n",
       "5           NaN     NaN      NaN  NaN  NaN      NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% Calculate distances from shore to dunes, etc.\n",
    "trans_df, dl2trans, dh2trans, arm2trans = fwa.calc_BeachWidth_fill(extendedTrans, trans_df, maxDH, tID_fld, MHW, fill)\n",
    "trans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dist2Inlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:0:1.7 seconds\n"
     ]
    }
   ],
   "source": [
    "# Dist2Inlet: Calc dist from inlets \n",
    "dist_df = fwa.measure_Dist2Inlet(shoreline, extendedTrans, inletLines, tID_fld)\n",
    "dist_df.to_pickle(os.path.join(scratch_dir, 'dist2inlet_df.pkl'))\n",
    "trans_df = fun.join_columns_id_check(trans_df, dist_df, tID_fld, fill=fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df.loc[187, 'Dist2Inlet']\n",
    "# trans_df['Dist2Inlet'].tail()\n",
    "# trans_df.loc[9:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip transects, get barrier widths *SPATIAL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the width along each transect of the oceanside land (WidthPart)...\n",
      "Converting feature class to array...\n",
      "Converting array to dataframe...\n",
      "Getting the width along each transect of the entire barrier (WidthFull)...\n",
      "Converting feature class vertices to array with X and Y...\n",
      "Converting array to dataframe...\n",
      "Getting the width along each transect of above water portion of the barrier (WidthLand)...\n"
     ]
    }
   ],
   "source": [
    "# Clip transects, get barrier widths *SPATIAL*\n",
    "widths_df = fwa.calc_IslandWidths(extendedTrans, barrierBoundary, tID_fld=tID_fld)\n",
    "trans_df = fun.join_columns_id_check(trans_df, widths_df, tID_fld, fill=fill)\n",
    "trans_df.to_pickle(os.path.join(scratch_dir, extTrans_null+'_prePts.pkl'))\n",
    "# trans_df = pd.read_pickle(os.path.join(scratch_dir, extTrans_null+'_prePts.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5m Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extTrans_tidy, barrierBoundary, transPts_presort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# if os.path.exists(os.path.join(scratch_dir, transPts_null+'.pkl')):\n",
    "#     pts_df = pd.read_pickle(os.path.join(scratch_dir,transPts_null+'.pkl'))\n",
    "#     trans_df = pd.read_pickle(os.path.join(scratch_dir, extTrans_null+'_prePts.pkl'))\n",
    "transPts_presort = os.path.join(arcpy.env.scratchGDB, transPts_presort)\n",
    "if not arcpy.Exists(transPts_presort):\n",
    "    pts_df, transPts_presort = fwa.TransectsToPointsDF(extTrans_tidy, barrierBoundary, fc_out=transPts_presort) # 4 minutes for FireIsland\n",
    "\n",
    "if not 'ptZ' in pts_df.columns:\n",
    "    # Extract elevation and slope at points\n",
    "    if not arcpy.Exists(elevGrid_5m):\n",
    "        fwa.ProcessDEM(elevGrid, elevGrid_5m, utmSR)\n",
    "    if not arcpy.Exists(slopeGrid):\n",
    "        arcpy.Slope_3d(elevGrid_5m, slopeGrid, 'PERCENT_RISE')\n",
    "    arcpy.sa.ExtractMultiValuesToPoints(transPts_presort, [[elevGrid_5m, 'ptZ'], [slopeGrid, 'ptSlp']]) # 9 min for ParkerRiver\n",
    "    pts_df = fwa.FCtoDF(transPts_presort, xy=True, dffields=[tID_fld,'ptZ', 'ptSlp'])\n",
    "    pts_df.to_pickle(os.path.join(scratch_dir, 'pts_df_elev_slope.pkl'))\n",
    "# pts_df = pd.read_pickle(os.path.join(scratch_dir, 'pts_df_elev_slope.pkl'))\n",
    "\n",
    "pts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate DistSeg, Dist_MHWbay, DistSegDH, DistSegDL, DistSegArm, sort points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# Calculate DistSeg, Dist_MHWbay, DistSegDH, DistSegDL, DistSegArm, sort points\n",
    "pts_df = fun.join_columns(pts_df, trans_df, tID_fld)\n",
    "pts_df = fun.prep_points(pts_df, tID_fld, pID_fld, MHW, fill)\n",
    "# Aggregate ptZmhw to max and mean and join to transPts and extendedTransects\n",
    "pts_df, zmhw = fun.aggregate_z(pts_df, MHW, tID_fld, 'ptZ', fill)\n",
    "trans_df = fun.join_columns(trans_df, zmhw) # join new fields to transects\n",
    "pts_df = fun.join_columns(pts_df, trans_df, tID_fld) # Join transect values to pts\n",
    "\n",
    "# Housecleaning\n",
    "trans_df.drop(extra_fields, axis=1, inplace=True, errors='ignore') # Drop extra fields\n",
    "pts_df.drop(extra_fields, axis=1, inplace=True, errors='ignore') # Drop extra fields\n",
    "\n",
    "#%% Save dataframes to open elsewhere or later\n",
    "trans_df.to_pickle(os.path.join(scratch_dir, extTrans_null+'.pkl'))\n",
    "pts_df.to_pickle(os.path.join(scratch_dir, transPts_null+'.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_df = pd.read_pickle(os.path.join(scratch_dir, transPts_null+'.pkl'))\n",
    "trans_df = pd.read_pickle(os.path.join(scratch_dir, extTrans_null+'.pkl'))\n",
    "pts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Join calculated transect values to the transect FC.\n",
    "trans_fc = fwa.JoinDFtoFC(trans_df, extendedTrans, tID_fld, out_fc=extTrans_fill)\n",
    "# DeleteExtraFields(trans_fc, trans_flds)\n",
    "fwa.CopyFCandReplaceValues(trans_fc, fill, None, out_fc=extTrans_null, out_dir=home)\n",
    "# Save final SHP with fill values\n",
    "arcpy.FeatureClassToFeatureClass_conversion(trans_fc, scratch_dir, extTrans_shp+'.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final pts with fill values as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Save final pts with fill values as CSV\n",
    "if not pID_fld in pts_df.columns:\n",
    "    pts_df.reset_index(drop=False, inplace=True)\n",
    "csv_fname = os.path.join(scratch_dir, transPts_fill +'.csv')\n",
    "pts_df.to_csv(os.path.join(scratch_dir, transPts_fill +'.csv'), na_rep=fill, index=False)\n",
    "print(\"OUTPUT: {}\".format(csv_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Beach Width raster by joining DF to ID raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Create Beach Width raster by joining DF to ID raster\n",
    "if not arcpy.Exists(rst_transIDpath):\n",
    "    outEucAll = arcpy.sa.EucAllocation(extTrans_tidy, maximum_distance=50, cell_size=cell_size, source_field=tID_fld)\n",
    "    outEucAll.save(os.path.basename(rst_transIDpath))\n",
    "out_rst = fwa.JoinDFtoRaster(trans_df, rst_transID, bw_rst, fill, tID_fld, 'uBW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pts_df to FC, both pts and trans (pts_fc, trans_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Convert pts_df to FC, both pts and trans (pts_fc, trans_fc)\n",
    "pts_fc = fwa.DFtoFC_large(pts_df, out_fc=os.path.join(arcpy.env.workspace, transPts_fill), spatial_ref=utmSR, df_id=pID_fld, xy=[\"seg_x\", \"seg_y\"])\n",
    "# DeleteExtraFields(pts_fc, pt_flds+trans_flds)\n",
    "# Save final FCs with null values, final SHP and XLS with fill values\n",
    "fwa.CopyFCandReplaceValues(pts_fc, fill, None, out_fc=transPts_null, out_dir=home)\n",
    "arcpy.FeatureClassToFeatureClass_conversion(pts_fc, scratch_dir, transPts_shp+'.shp')\n",
    "try:\n",
    "    xls_fname = os.path.join(scratch_dir, transPts_fill +'.xlsx')\n",
    "    pts_df.to_excel(xls_fname, na_rep=fill, index=False)\n",
    "    print(\"OUTPUT: {}\".format(xls_fname))\n",
    "except:\n",
    "    print(\"No Excel file created. You'll have to do it yourself from the CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
