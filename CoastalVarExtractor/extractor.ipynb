{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BI-geomorph-extraction\n",
    "\n",
    "Extract barrier island metrics along transects for Bayesian Network Deep Dive\n",
    "\n",
    "Requires: python 3, ArcPy\n",
    "\n",
    "Author: Emily Sturdivant\n",
    "\n",
    "email: esturdivant@usgs.gov; bgutierrez@usgs.gov\n",
    "\n",
    "Notes:\n",
    "- Run in ArcGIS Pro python 3 environment (access as: \\ArcGIS\\Pro\\bin\\Python\\Scripts\\proenv);\n",
    "- Spatial reference used is NAD 83 UTM 19N: arcpy.SpatialReference(26918)\n",
    "    \n",
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arcpy\n",
    "if os.path.basename(os.getcwd()) == 'BI-geomorph-extraction':\n",
    "    print('Module path is: {}'.format(os.getcwd()))\n",
    "    import CoastalVarExtractor.functions_warcpy as fwa\n",
    "    import CoastalVarExtractor.functions as fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod_path = \"C:\\Users\\esturdivant\\Code\\BI-geomorph-extraction\\CoastalVarExtractor\" # replace with path to module\n",
    "sys.path.append(mod_path)\n",
    "import CoastalVarExtractor.functions_warcpy as fwa\n",
    "import CoastalVarExtractor.functions as fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize variables\n",
    "\n",
    "Based on the project directory, and the site and year you have input, setvars.py will set a bunch of variables as the names of folders, files, and fields. 1) set-up the project folder and paths: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from CoastalVarExtractor.setvars import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transect-averaged values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Create trans_df\n",
    "trans_df = fwa.FCtoDF(extendedTransects, id_fld=tID_fld, extra_fields=extra_fields)\n",
    "if not os.path.exists(scratch_dir):\n",
    "    os.makedirs(scratch_dir)\n",
    "trans_df.to_pickle(os.path.join(scratch_dir, 'trans_df.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add XY and Z/slope from DH, DL, SL points within 10m of transects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Add XY and Z/slope from DH, DL, SL points within 10m of transects\n",
    "sl2trans_df = fwa.add_shorelinePts2Trans(extendedTransects, ShorelinePts, shoreline, tID_fld, proximity=pt2trans_disttolerance)\n",
    "sl2trans_df.to_pickle(os.path.join(scratch_dir, 'sl2trans.pkl'))\n",
    "fwa.DFtoFC(sl2trans_df, 'pts2trans_SL', spatial_ref=utmSR, id_fld=tID_fld, xy=[\"SL_x\", \"SL_y\"], keep_fields=['Bslope'])\n",
    "\n",
    "dh2trans_df = fwa.find_ClosestPt2Trans_snap(extendedTransects, dhPts, trans_df, 'DH', tID_fld, proximity=pt2trans_disttolerance)\n",
    "dh2trans_df.to_pickle(os.path.join(scratch_dir, 'dh2trans.pkl'))\n",
    "fwa.DFtoFC(dh2trans_df, 'ptSnap2trans_DH', spatial_ref=utmSR, id_fld=tID_fld, xy=[\"DH_snapX\", \"DH_snapY\"], keep_fields=['DH_z'])\n",
    "\n",
    "dl2trans_df = fwa.find_ClosestPt2Trans_snap(extendedTransects, dlPts, trans_df, 'DL', tID_fld, proximity=pt2trans_disttolerance)\n",
    "dl2trans_df.to_pickle(os.path.join(scratch_dir, 'dl2trans.pkl'))\n",
    "fwa.DFtoFC(dl2trans_df, 'ptSnap2trans_DL', spatial_ref=utmSR, id_fld=tID_fld, xy=[\"DL_snapX\", \"DL_snapY\"], keep_fields=['DL_z'])\n",
    "\n",
    "arm2trans_df = fwa.ArmorLineToTrans_PD(extendedTransects, armorLines, sl2trans_df, tID_fld, proj_code, elevGrid_5m)\n",
    "arm2trans_df.to_pickle(os.path.join(scratch_dir, 'arm2trans.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add all the positions to the trans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Add all the positions to the trans_df\n",
    "trans_df = fun.join_columns_id_check(trans_df, sl2trans_df, tID_fld)\n",
    "trans_df = fun.join_columns_id_check(trans_df, dh2trans_df, tID_fld)\n",
    "trans_df = fun.join_columns_id_check(trans_df, dl2trans_df, tID_fld)\n",
    "trans_df = fun.join_columns_id_check(trans_df, arm2trans_df, tID_fld)\n",
    "trans_df.to_pickle(os.path.join(scratch_dir, 'trans_df_beachmetrics.pkl'))\n",
    "\n",
    "#%% Calculate distances from shore to dunes, etc.\n",
    "trans_df, dl2trans, dh2trans, arm2trans = fwa.calc_BeachWidth_fill(extendedTransects, trans_df, maxDH, tID_fld, MHW, fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dist2Inlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Don't require trans_df\n",
    "# Dist2Inlet: Calc dist from inlets SPATIAL\n",
    "dist_df = fwa.measure_Dist2Inlet(shoreline, extendedTransects, inletLines, tID_fld)\n",
    "# dist_df.to_pickle(os.path.join(scratch_dir, 'dist2inlet_df.pkl'))\n",
    "trans_df = fun.join_columns_id_check(trans_df, dist_df, tID_fld, fill=fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip transects, get barrier widths *SPATIAL*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clip transects, get barrier widths *SPATIAL*\n",
    "widths_df = fwa.calc_IslandWidths(extendedTransects, barrierBoundary, tID_fld=tID_fld)\n",
    "trans_df = fun.join_columns_id_check(trans_df, widths_df, tID_fld, fill=fill)\n",
    "trans_df.to_pickle(os.path.join(scratch_dir, extTrans_null+'_prePts.pkl'))\n",
    "# trans_df = pd.read_pickle(os.path.join(scratch_dir, extTrans_null+'_prePts.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5m Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# if os.path.exists(os.path.join(scratch_dir, transPts_null+'.pkl')):\n",
    "#     pts_df = pd.read_pickle(os.path.join(scratch_dir,transPts_null+'.pkl'))\n",
    "#     trans_df = pd.read_pickle(os.path.join(scratch_dir, extTrans_null+'_prePts.pkl'))\n",
    "if not arcpy.Exists(transPts_presort):\n",
    "    pts_df, transPts_presort = fwa.TransectsToPointsDF(extTrans_tidy, barrierBoundary, fc_out=transPts_presort) # 4 minutes for FireIsland\n",
    "\n",
    "if not 'ptZ' in pts_df.columns:\n",
    "    # Extract elevation and slope at points\n",
    "    if not arcpy.Exists(elevGrid_5m):\n",
    "        fwa.ProcessDEM(elevGrid, elevGrid_5m, utmSR)\n",
    "    if not arcpy.Exists(slopeGrid):\n",
    "        arcpy.Slope_3d(elevGrid_5m, slopeGrid, 'PERCENT_RISE')\n",
    "    arcpy.sa.ExtractMultiValuesToPoints(transPts_presort, [[elevGrid_5m, 'ptZ'], [slopeGrid, 'ptSlp']]) # 9 min for ParkerRiver\n",
    "    pts_df = fwa.FCtoDF(transPts_presort, xy=True, dffields=[tID_fld,'ptZ', 'ptSlp'])\n",
    "    pts_df.to_pickle(os.path.join(scratch_dir, 'pts_df_elev_slope.pkl'))\n",
    "# pts_df = pd.read_pickle(os.path.join(scratch_dir, 'pts_df_elev_slope.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate DistSeg, Dist_MHWbay, DistSegDH, DistSegDL, DistSegArm, sort points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# Calculate DistSeg, Dist_MHWbay, DistSegDH, DistSegDL, DistSegArm, sort points\n",
    "pts_df = fun.join_columns(pts_df, trans_df, tID_fld)\n",
    "pts_df = fun.prep_points(pts_df, tID_fld, pID_fld, MHW, fill)\n",
    "# Aggregate ptZmhw to max and mean and join to transPts and extendedTransects\n",
    "pts_df, zmhw = fun.aggregate_z(pts_df, MHW, tID_fld, 'ptZ', fill)\n",
    "trans_df = fun.join_columns(trans_df, zmhw) # join new fields to transects\n",
    "pts_df = fun.join_columns(pts_df, trans_df, tID_fld) # Join transect values to pts\n",
    "\n",
    "# Housecleaning\n",
    "trans_df.drop(extra_fields, axis=1, inplace=True, errors='ignore') # Drop extra fields\n",
    "pts_df.drop(extra_fields, axis=1, inplace=True, errors='ignore') # Drop extra fields\n",
    "\n",
    "#%% Save dataframes to open elsewhere or later\n",
    "trans_df.to_pickle(os.path.join(scratch_dir, extTrans_null+'.pkl'))\n",
    "pts_df.to_pickle(os.path.join(scratch_dir, transPts_null+'.pkl'))\n",
    "# pts_df = pd.read_pickle(os.path.join(scratch_dir, transPts_null+'.pkl'))\n",
    "# trans_df = pd.read_pickle(os.path.join(scratch_dir, extTrans_null+'.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Join calculated transect values to the transect FC.\n",
    "trans_fc = fwa.JoinDFtoFC(trans_df, extendedTransects, tID_fld, out_fc=extTrans_fill)\n",
    "# DeleteExtraFields(trans_fc, trans_flds)\n",
    "fwa.CopyFCandReplaceValues(trans_fc, fill, None, out_fc=extTrans_null, out_dir=home)\n",
    "# Save final SHP with fill values\n",
    "arcpy.FeatureClassToFeatureClass_conversion(trans_fc, scratch_dir, extTrans_shp+'.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save final pts with fill values as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Save final pts with fill values as CSV\n",
    "if not pID_fld in pts_df.columns:\n",
    "    pts_df.reset_index(drop=False, inplace=True)\n",
    "csv_fname = os.path.join(scratch_dir, transPts_fill +'.csv')\n",
    "pts_df.to_csv(os.path.join(scratch_dir, transPts_fill +'.csv'), na_rep=fill, index=False)\n",
    "print(\"OUTPUT: {}\".format(csv_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Beach Width raster by joining DF to ID raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Create Beach Width raster by joining DF to ID raster\n",
    "if not arcpy.Exists(rst_transIDpath):\n",
    "    outEucAll = arcpy.sa.EucAllocation(orig_tidytrans, maximum_distance=50, cell_size=cell_size, source_field=tID_fld)\n",
    "    outEucAll.save(os.path.basename(rst_transIDpath))\n",
    "out_rst = fwa.JoinDFtoRaster(trans_df, rst_transID, bw_rst, fill, tID_fld, 'uBW')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pts_df to FC, both pts and trans (pts_fc, trans_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Convert pts_df to FC, both pts and trans (pts_fc, trans_fc)\n",
    "pts_fc = fwa.DFtoFC_large(pts_df, out_fc=os.path.join(arcpy.env.workspace, transPts_fill), spatial_ref=utmSR, df_id=pID_fld, xy=[\"seg_x\", \"seg_y\"])\n",
    "# DeleteExtraFields(pts_fc, pt_flds+trans_flds)\n",
    "# Save final FCs with null values, final SHP and XLS with fill values\n",
    "fwa.CopyFCandReplaceValues(pts_fc, fill, None, out_fc=transPts_null, out_dir=home)\n",
    "arcpy.FeatureClassToFeatureClass_conversion(pts_fc, scratch_dir, transPts_shp+'.shp')\n",
    "try:\n",
    "    xls_fname = os.path.join(scratch_dir, transPts_fill +'.xlsx')\n",
    "    pts_df.to_excel(xls_fname, na_rep=fill, index=False)\n",
    "    print(\"OUTPUT: {}\".format(xls_fname))\n",
    "except:\n",
    "    print(\"No Excel file created. You'll have to do it yourself from the CSV.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
